from sklearn import tree
from sklear.datasets import load_wine
from sklearn.model_selection import train_test_split


 # 8 parameters
 # random_state, splitter 随机性相关参数
 # max_depth, min_samples_split, min_samples_leaf, max_feature, min_impurity_decrease 剪枝参数
 # feature_importaces_ 一个属性
 # fit, score, apply, predict 四个接口




wine=load_wine()
wine.data
wine.data.shape
wine.target

import pandas as pd
pd.concat([pd.DataFrame(wine.data), pd.DataFrame(wine.target)], axis=1)
wine.feature_names
wine.target_names

Xtrain, Xtest, Ytrain, Ytest = train_test_split(wine.data, wine.target, test_size=0.3)

Xtrain.shape
Xtest.shape 

clf=tree.DecisionTreeClassifier(criterion="entropy"  
                                          ,random_state=30
                                          ,splitter="random"
                                          ,max_depth=3
                                         #,min_samples_leaf=10
                                        #,min_samples_split=25)
clf=clf.fit(Xtrain, Ytrain)
score=clf.score(Xtest, Ytest) #return accuracy of prediction
score



# draw a tree
import graphviz
dot_data=tree.export_graphviz(clf
                              , feature_names=wine.feature_names
                              , class_names=["1, "2, "3"]
                              , filled=True
                              , rounded=True

)

graph=graphviz.Source(dot_data)
graph
clf.feature_importances_
[*zip(wine.feature_names, clf.feature_importances_)]

import matplotlib.pyplot as plt
test=[]
for i in range(10)
  clf=tree.DecisionTreeClassifier(criterion="entropy"  
                                          ,random_state=30
                                          ,splitter="random"
                                          ,max_depth=i+1)
   
   clf=clf.fit(Xtrain, Ytrain)
   score=clf.score(x)
   score=clf.score(Xtest,Ytest)
   test.append(score)
plt.plot(range(1,11), test, color="red", label="max_depth")
plt.legend()
plt.show()
    

